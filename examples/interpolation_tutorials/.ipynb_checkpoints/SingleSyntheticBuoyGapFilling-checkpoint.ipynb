{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8c3f97c0-88ff-4847-8995-ade60da861c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import GPy\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from haversine import haversine, Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "1d422b8c-8ed3-4613-b4ca-749facc4c3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a manual Gaussian function\n",
    "def gaussian(x, mean, amplitude, stddev):\n",
    "    \"\"\"Generates a Gaussian curve.\"\"\"\n",
    "    return amplitude * np.exp(-((x - mean) ** 2) / (2 * stddev ** 2))\n",
    "\n",
    "# Gap fill function with spatial dependence applied at each time step\n",
    "def gap_fill_station_per_time(dataset, target_station_id, var_name='temperature'):\n",
    "    \"\"\"\n",
    "    Performs gap filling for a target station using data from surrounding stations.\n",
    "    Applies Gaussian Process Regression (GPR) at each time step, considering only spatial dependence.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataset: xarray.Dataset containing the station data\n",
    "    - target_station_id: The station ID of the target station to fill\n",
    "    - var_name: The name of the variable to be filled (e.g., 'temperature')\n",
    "    \n",
    "    Returns:\n",
    "    - filled_dataset: xarray.Dataset with filled values for the target station\n",
    "    - uncertainty_dataset: xarray.Dataset with uncertainty values (in same units as temperature)\n",
    "    \"\"\"\n",
    "    lat = dataset['lat'].values\n",
    "    lon = dataset['lon'].values\n",
    "    time = dataset['time'].values\n",
    "    n_time = len(time)\n",
    "\n",
    "    ref_lat, ref_lon = lat[target_station_id - 1], lon[target_station_id - 1]\n",
    "    \n",
    "    surrounding_stations = [id_ for id_ in dataset['station_id'].values if id_ != target_station_id]\n",
    "    target_data = dataset[var_name].sel(station_id=target_station_id).values\n",
    "\n",
    "    filled_data = target_data.copy()\n",
    "    gpr_std_all = np.empty_like(target_data)\n",
    "\n",
    "    # Normalize the lat/lon coordinates into a local Cartesian system\n",
    "    def latlon_to_local_cartesian(lat, lon, ref_lat, ref_lon):\n",
    "        x = np.array([haversine((ref_lat, lon[i]), (ref_lat, ref_lon), unit=Unit.KILOMETERS) for i in range(len(lon))])\n",
    "        y = np.array([haversine((lat[i], ref_lon), (ref_lat, ref_lon), unit=Unit.KILOMETERS) for i in range(len(lat))])\n",
    "        return x, y\n",
    "\n",
    "    # Prepare the target station's spatial coordinates (latitude and longitude)\n",
    "    x_target, y_target = latlon_to_local_cartesian([ref_lat], [ref_lon], ref_lat, ref_lon)\n",
    "\n",
    "    # Loop through each time step and apply GPR\n",
    "    for t in range(n_time):\n",
    "        valid_temp_list = []\n",
    "        x_all, y_all = [], []\n",
    "\n",
    "        # Gather data for this time step for all surrounding stations\n",
    "        for station_id in surrounding_stations:\n",
    "            data = dataset[var_name].sel(station_id=station_id).values\n",
    "            \n",
    "            # Check if the station has valid data at this time step\n",
    "            if not np.isnan(data[t]):\n",
    "                # Convert the lat/lon coordinates to Cartesian\n",
    "                x, y = latlon_to_local_cartesian([lat[station_id - 1]], [lon[station_id - 1]], ref_lat, ref_lon)\n",
    "                \n",
    "                # Append spatial coordinates and temperature data\n",
    "                x_all.append(x[0])\n",
    "                y_all.append(y[0])\n",
    "                valid_temp_list.append(data[t])\n",
    "\n",
    "        # Perform GPR only if there is valid data from surrounding stations\n",
    "        if len(valid_temp_list) > 0:\n",
    "            coords = np.column_stack([x_all, y_all])\n",
    "            valid_temp_all = np.array(valid_temp_list)[:, None]\n",
    "\n",
    "            # Use an RBF kernel with a bias term for spatial dependence\n",
    "            kernel = GPy.kern.RBF(input_dim=2, variance=10.0, lengthscale=1.0) + GPy.kern.Bias(input_dim=2)\n",
    "            \n",
    "            # Create and optimize the Gaussian Process model\n",
    "            gpr_model = GPy.models.GPRegression(coords, valid_temp_all, kernel)\n",
    "            gpr_model.optimize()\n",
    "\n",
    "            # Predict the missing value for the target station at this time step\n",
    "            target_coords = np.array([x_target[0], y_target[0]]).reshape(1, -1)\n",
    "            gpr_pred, gpr_var = gpr_model.predict(target_coords)\n",
    "\n",
    "\n",
    "            filled_data[t] = gpr_pred[0, 0]\n",
    "            gpr_std_all[t] = np.sqrt(gpr_var[0, 0])\n",
    "\n",
    "    # Return the filled dataset and uncertainty dataset as xarray\n",
    "    filled_dataset = xr.Dataset(\n",
    "        {var_name: (['time'], filled_data)},\n",
    "        coords={'time': dataset['time']}\n",
    "    )\n",
    "    \n",
    "    uncertainty_dataset = xr.Dataset(\n",
    "        {f'{var_name}_uncertainty': (['time'], gpr_std_all)},\n",
    "        coords={'time': dataset['time']}\n",
    "    )\n",
    "\n",
    "    return filled_dataset, uncertainty_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7962032-8b2d-46eb-b1d2-19a0c51edd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create synthetic buoy (station) data with lat/lon features and a spike\n",
    "n_time = 100\n",
    "n_stations = 10\n",
    "time = np.linspace(0, 10, n_time)\n",
    "station_ids = np.arange(1, n_stations + 1)\n",
    "latitudes = np.random.uniform(30, 40, n_stations)  # Random latitudes between 30째 and 35째\n",
    "longitudes = np.random.uniform(-81, -80, n_stations)  # Random longitudes between -90째 and -80째\n",
    "\n",
    "# Initialize an empty dataset with lat/lon\n",
    "dataset = xr.Dataset(coords={\"station_id\": station_ids, \"time\": time})\n",
    "dataset['lat'] = ('station_id', latitudes)\n",
    "dataset['lon'] = ('station_id', longitudes)\n",
    "\n",
    "# Define spike parameters\n",
    "spike_time = 5.0  # Physical time of the spike\n",
    "spike_duration = 6  # Spike duration in time steps\n",
    "spike_magnitude = 30.0  # The magnitude of the temperature spike\n",
    "spike_stddev = 0.5  # Gaussian spike width (stddev)\n",
    "\n",
    "# Create the Gaussian spike (pulse)\n",
    "x = np.linspace(-spike_duration // 2, spike_duration // 2, spike_duration)\n",
    "spike = gaussian(x, mean=0, amplitude=spike_magnitude, stddev=spike_stddev)\n",
    "\n",
    "dataset['temperature'] = (('station_id', 'time'), np.empty((n_stations, n_time)) * np.nan)\n",
    "# Generate data for each station and add the spike\n",
    "for i in range(n_stations):\n",
    "    base_data = (\n",
    "        20 + 5 * np.exp(-0.2 * time) + \n",
    "        np.sqrt(i + 1) * 1.5 * np.sin(2 * np.pi * time / 5) + \n",
    "        np.random.normal(0, 1, n_time) + ((np.exp(-latitudes[i] / 100) * np.sqrt(2 * i + 1))))\n",
    "    \n",
    "    # Apply the Gaussian spike to all stations at the same physical time\n",
    "    spike_time_index = np.argmin(np.abs(time - spike_time))\n",
    "    base_data[spike_time_index - spike_duration // 2 : spike_time_index + spike_duration // 2] += (np.exp(-latitudes[i] / 100) * spike)\n",
    "\n",
    "    # Add the data to the dataset\n",
    "    dataset['temperature'].isel(station_id=i).values[:] = base_data\n",
    "\n",
    "# Remove the spike from the target station (e.g., Station 2) to simulate missing data\n",
    "target_station_id = 2\n",
    "spike_time_index_target = np.argmin(np.abs(time - spike_time))\n",
    "old_target = 1 * dataset['temperature'].sel(station_id=target_station_id)\n",
    "dataset['temperature'].sel(station_id=target_station_id).isel(time=slice(spike_time_index_target - spike_duration, spike_time_index_target + spike_duration)).values[:] = np.nan\n",
    "\n",
    "# Gap fill for a specific station using the surrounding stations (including lat/lon)\n",
    "filled_data, uncertainty_data = gap_fill_station_per_time(dataset, target_station_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679671fe-7da5-4c28-864b-340921244f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the original, gap-filled data, and uncertainty with error bars\n",
    "time = dataset['time'].values\n",
    "original_data = dataset['temperature'].sel(station_id=target_station_id).values\n",
    "filled_values = filled_data['temperature'].values\n",
    "uncertainties = uncertainty_data['temperature_uncertainty'].values\n",
    "\n",
    "# Plotting the results (all in one plot)\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Gap-filled data with error bars\n",
    "plt.plot(time, filled_values, label='Gap-Filled Data', color='green')\n",
    "plt.fill_between(time, filled_values - (2 * uncertainties), filled_values + (2 * uncertainties), color='green', alpha=0.3, label='Uncertainty')\n",
    "\n",
    "# Original data with gaps\n",
    "plt.scatter(time, old_target.values, label='Original Data (No Gaps)', color='blue', marker='o')\n",
    "\n",
    "# Highlight the spike time on the plot\n",
    "plt.axvline(x=spike_time, color='red', linestyle='--', label='Spike Time')\n",
    "\n",
    "plt.title(f'Temperature Data for Station {target_station_id}')\n",
    "plt.ylabel('Temperature')\n",
    "plt.xlabel('Time')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plotting the results (all in one plot)\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Gap-filled data with error bars\n",
    "plt.plot(time, filled_values, label='Gap-Filled Data', color='green', marker='o')\n",
    "plt.fill_between(time, filled_values - (2 * uncertainties), filled_values + (2 * uncertainties), color='green', alpha=0.3, label='Uncertainty')\n",
    "\n",
    "# Original data with gaps\n",
    "plt.plot(time, original_data, label='Original Data (With Gaps)', color='blue', marker='o')\n",
    "\n",
    "# Highlight the spike time on the plot\n",
    "plt.axvline(x=spike_time, color='red', linestyle='--', label='Spike Time')\n",
    "\n",
    "plt.title(f'Temperature Data for Station {target_station_id}')\n",
    "plt.ylabel('Temperature')\n",
    "plt.xlabel('Time')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional figure: Plot temperature data from all stations and their distances from the target station\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot temperature data for all stations\n",
    "for i in range(n_stations):\n",
    "    station_data = dataset['temperature'].isel(station_id=i).values\n",
    "    plt.plot(time, station_data, label=f'Station {i + 1}')\n",
    "\n",
    "# Highlight the time of the spike\n",
    "plt.axvline(x=spike_time, color='red', linestyle='--', label='Spike Time')\n",
    "\n",
    "plt.title('Temperature Data for All Stations')\n",
    "plt.ylabel('Temperature')\n",
    "plt.xlabel('Time')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88724a67-c4d9-4f0a-af5e-ad9dcc34eea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f2340e-f63a-47df-bf02-c9ec27409471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
