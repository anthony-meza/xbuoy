{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85a062f7-804d-424e-adef-9428c6297d29",
   "metadata": {},
   "source": [
    "# Gaussian Process Regression (GPR) Explained - Part 1: Introduction\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "**Gaussian Process Regression (GPR)** is a non-parametric, Bayesian approach to regression. It provides not only predictions but also an estimate of the uncertainty in those predictions. GPR can be seen as a generalization of linear regression, but it allows for complex, non-linear relationships between the inputs and the outputs.\n",
    "\n",
    "In **linear regression**, the model is:\n",
    "\n",
    "$y = X\\beta + \\varepsilon$\n",
    "\n",
    "where:\n",
    "- $y$ is the vector of observed values.\n",
    "- $X$ is the matrix of input features.\n",
    "- $\\beta$ are the regression coefficients.\n",
    "- $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$ is Gaussian noise with zero mean and variance $\\sigma^2$.\n",
    "\n",
    "In GPR, we take a more flexible approach by assuming that the underlying function $f(\\mathbf{x})$ comes from a **Gaussian process**, rather than assuming a fixed linear form.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Gaussian Process\n",
    "\n",
    "### Definition\n",
    "\n",
    "A **Gaussian Process (GP)** is a collection of random variables, any finite number of which have a joint Gaussian distribution. A GP can be used to define a distribution over functions. \n",
    "\n",
    "We say that a function $f(\\mathbf{x})$ follows a Gaussian process if:\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x}) \\sim \\mathcal{GP}(m(\\mathbf{x}), k(\\mathbf{x}, \\mathbf{x}'))\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $m(\\mathbf{x})$ is the **mean function**, which describes the average value of the function at each point $\\mathbf{x}$. Typically, we assume $m(\\mathbf{x}) = 0$.\n",
    "- $k(\\mathbf{x}, \\mathbf{x}')$ is the **covariance function** (or kernel), which describes how the function values at $\\mathbf{x}$ and $\\mathbf{x}'$ are correlated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcb7804-4310-44e6-a2ed-180883e9aa35",
   "metadata": {},
   "source": [
    "# Gaussian Process Regression (GPR) Explained - Part 2: From Prior to Posterior\n",
    "\n",
    "## 3. GPR: From Prior to Posterior\n",
    "\n",
    "In GPR, we place a **prior** on the function $f(\\mathbf{x})$ by assuming that it follows a Gaussian process. The goal is to update this prior with observed data to obtain a **posterior distribution** over the functions, which can be used to make predictions at new points.\n",
    "\n",
    "### Problem Setup\n",
    "\n",
    "Given training data $\\mathcal{D} = \\{ (\\mathbf{x}_i, y_i) \\}_{i=1}^n$, we assume:\n",
    "\n",
    "$$\n",
    "y_i = f(\\mathbf{x}_i) + \\varepsilon_i\n",
    "$$\n",
    "\n",
    "where $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma_n^2)$ is Gaussian noise with variance $\\sigma_n^2$.\n",
    "\n",
    "### Joint Distribution of Training and Test Points\n",
    "\n",
    "Let $f_* = f(\\mathbf{x}_*)$ be the function value at a new test point $\\mathbf{x}_*$. The joint distribution of the function values at the training points $\\mathbf{X}$ and the function value at the test point $\\mathbf{x}_*$ is also Gaussian:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "f(\\mathbf{X}) \\\\\n",
    "f_*\n",
    "\\end{bmatrix}\n",
    "\\sim \\mathcal{N} \\left( 0, \\begin{bmatrix}\n",
    "K(\\mathbf{X}, \\mathbf{X}) & K(\\mathbf{X}, \\mathbf{x}_*) \\\\\n",
    "K(\\mathbf{x}_*, \\mathbf{X}) & k(\\mathbf{x}_*, \\mathbf{x}_*)\n",
    "\\end{bmatrix} \\right)\n",
    "$$\n",
    "\n",
    "Here:\n",
    "- $K(\\mathbf{X}, \\mathbf{X})$ is the covariance matrix of the training points.\n",
    "- $K(\\mathbf{X}, \\mathbf{x}_*)$ is the vector of covariances between the training points and the test point.\n",
    "- $k(\\mathbf{x}_*, \\mathbf{x}_*)$ is the variance of the test point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320bb7f1-d8e2-4907-b681-4c46e28794e6",
   "metadata": {},
   "source": [
    "# Gaussian Process Regression (GPR) Explained - Part 3: Noisy Observations and Posterior Distribution\n",
    "\n",
    "## 4. Incorporating Noisy Observations\n",
    "\n",
    "In practice, we donâ€™t observe the true function values $f(\\mathbf{X})$; instead, we observe noisy versions $y = f(\\mathbf{X}) + \\varepsilon$, where $\\varepsilon \\sim \\mathcal{N}(0, \\sigma_n^2 I)$ is Gaussian noise with variance $\\sigma_n^2$.\n",
    "\n",
    "Thus, the covariance matrix of the **observed outputs** $y$ is:\n",
    "\n",
    "$$\n",
    "\\text{Cov}(y) = K(\\mathbf{X}, \\mathbf{X}) + \\sigma_n^2 I\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Conditioning to Get the Posterior Distribution\n",
    "\n",
    "We now want to compute the **posterior distribution** of the function value $f_*$ at the test point $\\mathbf{x}_*$, conditioned on the observed data $y$.\n",
    "\n",
    "Using the properties of multivariate Gaussians, the posterior distribution of $f_*$ is also Gaussian with:\n",
    "\n",
    "### Posterior Mean\n",
    "\n",
    "$$\n",
    "\\mu_* = K(\\mathbf{x}_*, \\mathbf{X}) [K(\\mathbf{X}, \\mathbf{X}) + \\sigma_n^2 I]^{-1} \\mathbf{y}\n",
    "$$\n",
    "\n",
    "This is the best estimate of $f_*$ at $\\mathbf{x}_*$ given the observed data.\n",
    "\n",
    "### Posterior Variance\n",
    "\n",
    "$$\n",
    "\\sigma_*^2 = k(\\mathbf{x}_*, \\mathbf{x}_*) - K(\\mathbf{x}_*, \\mathbf{X}) [K(\\mathbf{X}, \\mathbf{X}) + \\sigma_n^2 I]^{-1} K(\\mathbf{X}, \\mathbf{x}_*)\n",
    "$$\n",
    "\n",
    "This tells us how uncertain the prediction is at the test point $\\mathbf{x}_*$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c7fd4c-d441-4505-95f1-a45620275d77",
   "metadata": {},
   "source": [
    "# Gaussian Process Regression (GPR) Explained - Part 4: Simple Example\n",
    "\n",
    "## 6. Simple Example\n",
    "\n",
    "Consider a simple 1D example where we have 3 training points $X = [1, 2, 3]$ and corresponding noisy observations $y = [1.1, 1.9, 3.2]$. We want to predict the function value $f_*$ at a new point $x_* = 1.5$.\n",
    "\n",
    "### 1. Define the Covariance Function\n",
    "\n",
    "We'll use the **squared exponential (RBF)** kernel:\n",
    "\n",
    "$$\n",
    "k(x, x') = \\sigma_f^2 \\exp\\left( -\\frac{(x - x')^2}{2l^2} \\right)\n",
    "$$\n",
    "\n",
    "where $\\sigma_f^2 = 1$ and $l = 1$ are the signal variance and length scale, respectively.\n",
    "\n",
    "### 2. Compute the Covariance Matrices\n",
    "\n",
    "- **Covariance matrix for training points**:\n",
    "\n",
    "$$\n",
    "K(X, X) = \\begin{bmatrix}\n",
    "k(1, 1) & k(1, 2) & k(1, 3) \\\\\n",
    "k(2, 1) & k(2, 2) & k(2, 3) \\\\\n",
    "k(3, 1) & k(3, 2) & k(3, 3)\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "1.0 & 0.6065 & 0.1353 \\\\\n",
    "0.6065 & 1.0 & 0.6065 \\\\\n",
    "0.1353 & 0.6065 & 1.0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- **Covariance vector between training points and the test point**:\n",
    "\n",
    "$$\n",
    "K(X, x_*) = \\begin{bmatrix}\n",
    "k(1, 1.5) \\\\\n",
    "k(2, 1.5) \\\\\n",
    "k(3, 1.5)\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "0.8825 \\\\\n",
    "0.8825 \\\\\n",
    "0.3247\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- **Variance at the test point**:\n",
    "\n",
    "$$\n",
    "k(x_*, x_*) = k(1.5, 1.5) = 1\n",
    "$$\n",
    "\n",
    "### 3. Compute the Posterior Mean and Variance\n",
    "\n",
    "- **Posterior mean**:\n",
    "\n",
    "$$\n",
    "\\mu_* = K(x_*, X) [K(X, X) + \\sigma_n^2 I]^{-1} y\n",
    "$$\n",
    "\n",
    "where $\\sigma_n^2 = 0.1^2 = 0.01$ is the noise variance.\n",
    "\n",
    "- **Posterior variance**:\n",
    "\n",
    "$$\n",
    "\\sigma_*^2 = k(x_*, x_*) - K(x_*, X) [K(X, X) + \\sigma_n^2 I]^{-1} K(X, x_*)\n",
    "$$\n",
    "\n",
    "This tells us both the predicted function value $\\mu_*$ and the uncertainty $\\sigma_*^2$ at the test point $x_* = 1.5$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5187277-ef13-45a3-a11c-ebf2771b60d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
